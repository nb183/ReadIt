{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ReadIT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HxvCm_OLRgP"
      },
      "source": [
        "# Downloading pretrained model (intensive one)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzphpaM0LZ6a"
      },
      "source": [
        "## Download model 4 from codalab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndlyviKgpNHZ",
        "outputId": "192eff72-be27-4050-8578-a2d8144ff93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "!wget https://worksheets.codalab.org/rest/bundles/0x6ac39bac7de2473eb13f737ce4657c56/contents/blob/ -O model4.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-28 08:22:55--  https://worksheets.codalab.org/rest/bundles/0x6ac39bac7de2473eb13f737ce4657c56/contents/blob/\n",
            "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.114.41.203\n",
            "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.114.41.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Syntax error in Set-Cookie: codalab_session=\"\"; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=-1; Path=/ at position 70.\n",
            "Length: unspecified [application/gzip]\n",
            "Saving to: ‘model4.tar.gz’\n",
            "\n",
            "model4.tar.gz           [  <=>               ] 787.72M  14.7MB/s    in 55s     \n",
            "\n",
            "2020-10-28 08:23:50 (14.3 MB/s) - ‘model4.tar.gz’ saved [825983721]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32rgiwbaLm2f"
      },
      "source": [
        "## Extract gipped tarball in model4 directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KUCvJpepdNS"
      },
      "source": [
        "!mkdir model4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruHzDnGRqb0p",
        "outputId": "9feefbe4-a4a1-4962-a12c-0233b9146bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "  !tar -xvf model4.tar.gz -C model4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./\n",
            "./config.json\n",
            "./pytorch_model.bin\n",
            "./spiece.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3fde4OdLtIO"
      },
      "source": [
        "# Download min version of dev dataset of sqaud 2.0 from discord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2bbDP83qxUK",
        "outputId": "13239d89-1214-4216-c370-0566db4bc1af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "!wget https://cdn.discordapp.com/attachments/747371615951519758/760556617916743680/dev-v2.0.json -O dev-v2.0.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-28 08:28:04--  https://cdn.discordapp.com/attachments/747371615951519758/760556617916743680/dev-v2.0.json\n",
            "Resolving cdn.discordapp.com (cdn.discordapp.com)... 162.159.135.233, 162.159.133.233, 162.159.130.233, ...\n",
            "Connecting to cdn.discordapp.com (cdn.discordapp.com)|162.159.135.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76181 (74K) [application/json]\n",
            "Saving to: ‘dev-v2.0.json’\n",
            "\n",
            "\rdev-v2.0.json         0%[                    ]       0  --.-KB/s               \rdev-v2.0.json       100%[===================>]  74.40K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2020-10-28 08:28:04 (5.61 MB/s) - ‘dev-v2.0.json’ saved [76181/76181]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShWg_SklL3vu"
      },
      "source": [
        "# Download code base from GitHub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG6G3pfcL8V7"
      },
      "source": [
        "NOTE: **The token has expiry date since the repo is private** You may need to update the token my downloading in your device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP3gej1qrVWt",
        "outputId": "52ce9e46-a938-4e14-d6bd-0b54a9bcf5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "!wget https://codeload.github.com/rabinadk1/ReadIt/zip/master?token=AIKYJ7KV7D5NCF3ZYN6QO527TEXWM -O master.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-28 08:40:21--  https://codeload.github.com/rabinadk1/ReadIt/zip/master?token=AIKYJ7KV7D5NCF3ZYN6QO527TEXWM\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [  <=>               ]   2.40M  10.2MB/s    in 0.2s    \n",
            "\n",
            "2020-10-28 08:40:21 (10.2 MB/s) - ‘master.zip’ saved [2514437]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDrAE5WrMInm"
      },
      "source": [
        "## Unzipped the zip file downloaded above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhKS5Bn-uAK7",
        "outputId": "2d93d3d0-90a4-45f5-c619-072b8f0407f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!unzip master.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  master.zip\n",
            "25f72d71d2052d864849afc1d3bf9971f3f88e1e\n",
            "   creating: ReadIt-master/\n",
            "  inflating: ReadIt-master/.gitignore  \n",
            "   creating: ReadIt-master/examples/\n",
            " extracting: ReadIt-master/examples/__init__.py  \n",
            "  inflating: ReadIt-master/examples/benchmarks.py  \n",
            "   creating: ReadIt-master/examples/contrib/\n",
            "  inflating: ReadIt-master/examples/contrib/README.md  \n",
            "  inflating: ReadIt-master/examples/contrib/run_camembert.py  \n",
            "  inflating: ReadIt-master/examples/contrib/run_openai_gpt.py  \n",
            "  inflating: ReadIt-master/examples/contrib/run_swag.py  \n",
            "  inflating: ReadIt-master/examples/contrib/run_transfo_xl.py  \n",
            "   creating: ReadIt-master/examples/distillation/\n",
            "  inflating: ReadIt-master/examples/distillation/README.md  \n",
            "  inflating: ReadIt-master/examples/distillation/distiller.py  \n",
            "  inflating: ReadIt-master/examples/distillation/grouped_batch_sampler.py  \n",
            "  inflating: ReadIt-master/examples/distillation/lm_seqs_dataset.py  \n",
            "  inflating: ReadIt-master/examples/distillation/requirements.txt  \n",
            "  inflating: ReadIt-master/examples/distillation/run_squad_w_distillation.py  \n",
            "   creating: ReadIt-master/examples/distillation/scripts/\n",
            "  inflating: ReadIt-master/examples/distillation/scripts/binarized_data.py  \n",
            "  inflating: ReadIt-master/examples/distillation/scripts/extract.py  \n",
            "  inflating: ReadIt-master/examples/distillation/scripts/extract_distilbert.py  \n",
            "  inflating: ReadIt-master/examples/distillation/scripts/token_counts.py  \n",
            "  inflating: ReadIt-master/examples/distillation/train.py  \n",
            "   creating: ReadIt-master/examples/distillation/training_configs/\n",
            "  inflating: ReadIt-master/examples/distillation/training_configs/distilbert-base-uncased.json  \n",
            "  inflating: ReadIt-master/examples/distillation/training_configs/distilgpt2.json  \n",
            "  inflating: ReadIt-master/examples/distillation/utils.py  \n",
            "  inflating: ReadIt-master/examples/evaluate_official2.py  \n",
            "   creating: ReadIt-master/examples/pplm/\n",
            "  inflating: ReadIt-master/examples/pplm/README.md  \n",
            "   creating: ReadIt-master/examples/pplm/imgs/\n",
            "  inflating: ReadIt-master/examples/pplm/imgs/headfigure.png  \n",
            "  inflating: ReadIt-master/examples/pplm/imgs/wooly.png  \n",
            "  inflating: ReadIt-master/examples/pplm/pplm_classification_head.py  \n",
            "  inflating: ReadIt-master/examples/pplm/run_pplm.py  \n",
            "  inflating: ReadIt-master/examples/pplm/run_pplm_discrim_train.py  \n",
            "  inflating: ReadIt-master/examples/requirements.txt  \n",
            "  inflating: ReadIt-master/examples/run_bertology.py  \n",
            "  inflating: ReadIt-master/examples/run_cls.py  \n",
            "  inflating: ReadIt-master/examples/run_squad.py  \n",
            "  inflating: ReadIt-master/examples/run_squad_av.py  \n",
            "  inflating: ReadIt-master/examples/run_squad_av_all.py  \n",
            "  inflating: ReadIt-master/examples/run_squad_av_bce.py  \n",
            "  inflating: ReadIt-master/examples/run_squad_avreg.py  \n",
            "  inflating: ReadIt-master/examples/run_squad_dep.py  \n",
            "  inflating: ReadIt-master/examples/run_squad_seq_sc.py  \n",
            "  inflating: ReadIt-master/examples/run_squad_seq_trm.py  \n",
            "  inflating: ReadIt-master/examples/run_verifier.py  \n",
            "   creating: ReadIt-master/examples/runs/\n",
            "   creating: ReadIt-master/examples/runs/May14_17-05-20_LAPTOP-35F8BIJU/\n",
            "  inflating: ReadIt-master/examples/runs/May14_17-05-20_LAPTOP-35F8BIJU/events.out.tfevents.1589443520.LAPTOP-35F8BIJU.17892.0  \n",
            "   creating: ReadIt-master/examples/summarization/\n",
            "  inflating: ReadIt-master/examples/summarization/README.md  \n",
            "  inflating: ReadIt-master/examples/summarization/configuration_bertabs.py  \n",
            "  inflating: ReadIt-master/examples/summarization/convert_bertabs_original_pytorch_checkpoint.py  \n",
            "  inflating: ReadIt-master/examples/summarization/modeling_bertabs.py  \n",
            "  inflating: ReadIt-master/examples/summarization/requirements.txt  \n",
            "  inflating: ReadIt-master/examples/summarization/run_summarization.py  \n",
            "  inflating: ReadIt-master/examples/summarization/utils_summarization.py  \n",
            "  inflating: ReadIt-master/examples/summarization/utils_summarization_test.py  \n",
            "   creating: ReadIt-master/examples/tests_samples/\n",
            "  inflating: ReadIt-master/examples/tests_samples/.gitignore  \n",
            "   creating: ReadIt-master/examples/tests_samples/MRPC/\n",
            "  inflating: ReadIt-master/examples/tests_samples/MRPC/dev.tsv  \n",
            "  inflating: ReadIt-master/examples/tests_samples/MRPC/train.tsv  \n",
            "   creating: ReadIt-master/examples/tests_samples/SQUAD/\n",
            "  inflating: ReadIt-master/examples/tests_samples/SQUAD/dev-v2.0.json  \n",
            "  inflating: ReadIt-master/examples/tests_samples/SQUAD/train-v2.0.json  \n",
            "  inflating: ReadIt-master/examples/utils_multiple_choice.py  \n",
            "  inflating: ReadIt-master/examples/utils_ner.py  \n",
            "  inflating: ReadIt-master/sh_albert_av.sh  \n",
            "  inflating: ReadIt-master/sh_albert_cls.sh  \n",
            "  inflating: ReadIt-master/sh_albert_seq_trm.sh  \n",
            "   creating: ReadIt-master/transformers/\n",
            "  inflating: ReadIt-master/transformers/__init__.py  \n",
            "  inflating: ReadIt-master/transformers/__main__.py  \n",
            "   creating: ReadIt-master/transformers/commands/\n",
            "  inflating: ReadIt-master/transformers/commands/__init__.py  \n",
            "  inflating: ReadIt-master/transformers/commands/convert.py  \n",
            "  inflating: ReadIt-master/transformers/commands/download.py  \n",
            "  inflating: ReadIt-master/transformers/commands/run.py  \n",
            "  inflating: ReadIt-master/transformers/commands/serving.py  \n",
            "  inflating: ReadIt-master/transformers/commands/train.py  \n",
            "  inflating: ReadIt-master/transformers/commands/user.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_albert.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_auto.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_bert.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_camembert.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_ctrl.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_distilbert.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_gpt2.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_openai.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_roberta.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_t5.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_transfo_xl.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_utils.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_xlm.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_xlm_roberta.py  \n",
            "  inflating: ReadIt-master/transformers/configuration_xlnet.py  \n",
            "  inflating: ReadIt-master/transformers/convert_albert_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: ReadIt-master/transformers/convert_bert_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: ReadIt-master/transformers/convert_bert_pytorch_checkpoint_to_original_tf.py  \n",
            "  inflating: ReadIt-master/transformers/convert_gpt2_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: ReadIt-master/transformers/convert_openai_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: ReadIt-master/transformers/convert_pytorch_checkpoint_to_tf2.py  \n",
            "  inflating: ReadIt-master/transformers/convert_roberta_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: ReadIt-master/transformers/convert_t5_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: ReadIt-master/transformers/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: ReadIt-master/transformers/convert_xlm_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: ReadIt-master/transformers/convert_xlnet_original_tf_checkpoint_to_pytorch.py  \n",
            "   creating: ReadIt-master/transformers/data/\n",
            "  inflating: ReadIt-master/transformers/data/__init__.py  \n",
            "   creating: ReadIt-master/transformers/data/metrics/\n",
            "  inflating: ReadIt-master/transformers/data/metrics/__init__.py  \n",
            "  inflating: ReadIt-master/transformers/data/metrics/squad_metrics.py  \n",
            "   creating: ReadIt-master/transformers/data/processors/\n",
            "  inflating: ReadIt-master/transformers/data/processors/__init__.py  \n",
            "  inflating: ReadIt-master/transformers/data/processors/glue.py  \n",
            "  inflating: ReadIt-master/transformers/data/processors/squad.py  \n",
            "  inflating: ReadIt-master/transformers/data/processors/utils.py  \n",
            "  inflating: ReadIt-master/transformers/data/processors/xnli.py  \n",
            "  inflating: ReadIt-master/transformers/file_utils.py  \n",
            "  inflating: ReadIt-master/transformers/hf_api.py  \n",
            "  inflating: ReadIt-master/transformers/modelcard.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_albert.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_auto.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_bert.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_camembert.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_ctrl.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_distilbert.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_encoder_decoder.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_gpt2.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_openai.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_roberta.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_t5.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_albert.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_auto.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_bert.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_ctrl.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_distilbert.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_gpt2.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_openai.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_pytorch_utils.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_roberta.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_t5.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_transfo_xl.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_transfo_xl_utilities.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_utils.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_xlm.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_tf_xlnet.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_transfo_xl.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_transfo_xl_utilities.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_utils.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_xlm.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_xlm_roberta.py  \n",
            "  inflating: ReadIt-master/transformers/modeling_xlnet.py  \n",
            "  inflating: ReadIt-master/transformers/optimization.py  \n",
            "  inflating: ReadIt-master/transformers/optimization_tf.py  \n",
            "  inflating: ReadIt-master/transformers/pipelines.py  \n",
            "   creating: ReadIt-master/transformers/tests/\n",
            " extracting: ReadIt-master/transformers/tests/__init__.py  \n",
            "  inflating: ReadIt-master/transformers/tests/configuration_common_test.py  \n",
            "   creating: ReadIt-master/transformers/tests/fixtures/\n",
            " extracting: ReadIt-master/transformers/tests/fixtures/empty.txt  \n",
            "  inflating: ReadIt-master/transformers/tests/fixtures/input.txt  \n",
            "  inflating: ReadIt-master/transformers/tests/fixtures/sample_text.txt  \n",
            "  inflating: ReadIt-master/transformers/tests/fixtures/spiece.model  \n",
            "  inflating: ReadIt-master/transformers/tests/fixtures/test_sentencepiece.model  \n",
            "  inflating: ReadIt-master/transformers/tests/hf_api_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/model_card_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_albert_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_auto_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_bert_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_common_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_ctrl_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_distilbert_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_encoder_decoder_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_gpt2_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_openai_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_roberta_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_t5_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_albert_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_auto_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_bert_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_common_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_ctrl_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_distilbert_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_gpt2_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_openai_gpt_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_roberta_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_t5_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_transfo_xl_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_xlm_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_tf_xlnet_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_transfo_xl_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_xlm_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/modeling_xlnet_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/optimization_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/optimization_tf_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/pipelines_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_albert_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_auto_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_bert_japanese_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_bert_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_ctrl_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_distilbert_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_gpt2_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_openai_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_roberta_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_t5_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_tests_commons.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_transfo_xl_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_utils_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_xlm_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/tokenization_xlnet_test.py  \n",
            "  inflating: ReadIt-master/transformers/tests/utils.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_albert.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_auto.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_bert.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_bert_japanese.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_camembert.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_ctrl.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_distilbert.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_gpt2.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_openai.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_roberta.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_t5.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_transfo_xl.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_utils.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_xlm.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_xlm_roberta.py  \n",
            "  inflating: ReadIt-master/transformers/tokenization_xlnet.py  \n",
            "   creating: ReadIt-master/utils/\n",
            "  inflating: ReadIt-master/utils/download_glue_data.py  \n",
            "  inflating: ReadIt-master/utils/link_tester.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hkw9J7lMYKp"
      },
      "source": [
        "# Permanently change the directory for colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jETh0eUuJ6N",
        "outputId": "e9bbb376-7553-4b5e-e5d5-6dbed3716d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "%cd ReadIt-master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ReadIt-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0oYKlTXMcwN"
      },
      "source": [
        "# Install required packages from `examples/requirement.txt`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awn_wpDpuRyI",
        "outputId": "fb7e2438-1d3c-401a-bbd6-98cc3cc34041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "source": [
        "!pip3 install -r examples/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r examples/requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r examples/requirements.txt (line 3)) (0.22.2.post1)\n",
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r examples/requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r examples/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r examples/requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r examples/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r examples/requirements.txt (line 2)) (50.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r examples/requirements.txt (line 2)) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r examples/requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r examples/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r examples/requirements.txt (line 2)) (0.35.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r examples/requirements.txt (line 2)) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r examples/requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r examples/requirements.txt (line 2)) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r examples/requirements.txt (line 2)) (1.33.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r examples/requirements.txt (line 3)) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r examples/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard->-r examples/requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r examples/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r examples/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r examples/requirements.txt (line 2)) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r examples/requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r examples/requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r examples/requirements.txt (line 2)) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r examples/requirements.txt (line 2)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r examples/requirements.txt (line 2)) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->-r examples/requirements.txt (line 2)) (3.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r examples/requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard->-r examples/requirements.txt (line 2)) (0.4.8)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=b7e56f87ff4608bda238e06b38faf68bcb896e406185d5de6b68c17e1d120615\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: tensorboardX, seqeval\n",
            "Successfully installed seqeval-1.2.2 tensorboardX-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJrt6iL-vv_r",
        "outputId": "08fa6333-b975-48a0-befb-c3b16aedf3c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "examples\t sh_albert_cls.sh      transformers\n",
            "sh_albert_av.sh  sh_albert_seq_trm.sh  utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXnW9lQ3NClq"
      },
      "source": [
        "## Install additional dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt-2abxyumrI",
        "outputId": "46c27625-b8df-4f00-d78a-a09f8583422d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        }
      },
      "source": [
        "!pip3 install sentencepiece boto3 sacremoses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 2.8MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/d9/e8a56bd0953914f60207af4c41bb3947c47ca03577b1fe26258249dd9af7/boto3-1.16.6-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 16.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 15.2MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.20.0,>=1.19.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/6c/f5b074e14823f250e0a73e53714c1ed80d689d530468936d35a9d336f1dd/botocore-1.19.6-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 17.6MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from sacremoses) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses) (0.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sacremoses) (4.41.1)\n",
            "Collecting urllib3<1.26,>=1.25.4; python_version != \"3.4\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/aa/4ef5aa67a9a62505db124a5cb5262332d1d4153462eb8fd89c9fa41e5d92/urllib3-1.25.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 47.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.6->boto3) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=f135ec19cf17bc225cf37e77a11e9bb62795d0a5e743f5c8c43b2b31eb9393a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, jmespath, urllib3, botocore, s3transfer, boto3, sacremoses\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed boto3-1.16.6 botocore-1.19.6 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 urllib3-1.25.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1TkMODkMlvr"
      },
      "source": [
        "# Run intensive reader model downloaded above on dev.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_JjrQCgz9wU",
        "outputId": "38d8e0b0-5393-42a5-9d24-d703410a6978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 -m examples.run_squad \\\n",
        "    --model_type albert \\\n",
        "    --model_name_or_path ../model4 \\\n",
        "    --do_eval \\\n",
        "    --do_lower_case \\\n",
        "    --version_2_with_negative \\\n",
        "    --predict_file ../dev-v2.0.json \\\n",
        "    --max_seq_length 512 \\\n",
        "    --n_best_size=20 \\\n",
        "    --max_answer_length=30 \\\n",
        "    --doc_stride 128 \\\n",
        "    --max_query_length=64 \\\n",
        "    --per_gpu_eval_batch_size=16 \\\n",
        "    --output_dir ../prediction4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-28 08:42:59.407088: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "10/28/2020 08:43:02 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "10/28/2020 08:43:02 - INFO - transformers.configuration_utils -   loading configuration file ../model4/config.json\n",
            "10/28/2020 08:43:02 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "10/28/2020 08:43:02 - INFO - transformers.tokenization_utils -   Model name '../model4' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming '../model4' is a path or url to a directory containing tokenizer files.\n",
            "10/28/2020 08:43:02 - INFO - transformers.tokenization_utils -   Didn't find file ../model4/added_tokens.json. We won't load it.\n",
            "10/28/2020 08:43:02 - INFO - transformers.tokenization_utils -   Didn't find file ../model4/special_tokens_map.json. We won't load it.\n",
            "10/28/2020 08:43:02 - INFO - transformers.tokenization_utils -   Didn't find file ../model4/tokenizer_config.json. We won't load it.\n",
            "10/28/2020 08:43:02 - INFO - transformers.tokenization_utils -   loading file ../model4/spiece.model\n",
            "10/28/2020 08:43:02 - INFO - transformers.tokenization_utils -   loading file None\n",
            "10/28/2020 08:43:02 - INFO - transformers.tokenization_utils -   loading file None\n",
            "10/28/2020 08:43:02 - INFO - transformers.tokenization_utils -   loading file None\n",
            "10/28/2020 08:43:02 - INFO - transformers.modeling_utils -   loading weights file ../model4/pytorch_model.bin\n",
            "10/28/2020 08:43:11 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in AlbertForQuestionAnswering: ['has_ans.1.weight', 'has_ans.1.bias']\n",
            "10/28/2020 08:43:11 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='', device=device(type='cpu'), do_eval=True, do_lower_case=True, do_train=False, doc_stride=128, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=512, max_steps=-1, model_name_or_path='../model4', model_type='albert', n_best_size=20, n_gpu=0, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='../prediction4', overwrite_cache=False, overwrite_output_dir=False, padding_side='right', per_gpu_eval_batch_size=16, per_gpu_train_batch_size=8, predict_file='../dev-v2.0.json', save_steps=50, seed=42, server_ip='', server_port='', tokenizer_name='', train_file=None, verbose_logging=False, version_2_with_negative=True, warmup_steps=0, weight_decay=0.0)\n",
            "10/28/2020 08:43:11 - INFO - __main__ -   Loading checkpoint ../model4 for evaluation\n",
            "10/28/2020 08:43:11 - INFO - __main__ -   Evaluate the following checkpoints: ['../model4']\n",
            "10/28/2020 08:43:11 - INFO - transformers.configuration_utils -   loading configuration file ../model4/config.json\n",
            "10/28/2020 08:43:11 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "10/28/2020 08:43:11 - INFO - transformers.modeling_utils -   loading weights file ../model4/pytorch_model.bin\n",
            "10/28/2020 08:43:21 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in AlbertForQuestionAnswering: ['has_ans.1.weight', 'has_ans.1.bias']\n",
            "10/28/2020 08:43:21 - INFO - __main__ -   Creating features from dataset file at .\n",
            "100% 1/1 [00:00<00:00, 16.21it/s]\n",
            "Converting examples to features: 100% 208/208 [00:01<00:00, 189.25it/s]\n",
            "10/28/2020 08:43:22 - INFO - __main__ -   Saving features into cached file ./cached_dev_model4_512\n",
            "10/28/2020 08:43:22 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "10/28/2020 08:43:22 - INFO - __main__ -     Num examples = 208\n",
            "10/28/2020 08:43:22 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating:   0% 0/13 [00:00<?, ?it/s]tcmalloc: large alloc 1073741824 bytes == 0x25be8000 @  0x7f08ee710b6b 0x7f08ee730379 0x7f089ac7992e 0x7f089ac7b946 0x7f08d3057bb3 0x7f08d2b0c17a 0x7f08d2b0d293 0x7f08d300dedf 0x7f08d29d70aa 0x7f08d29da407 0x7f08d29da500 0x7f08d2df18b9 0x7f08d274f530 0x7f08d2f3781c 0x7f08d2e87feb 0x7f08d4b40948 0x7f08d274f530 0x7f08d2f3781c 0x7f08d301d5eb 0x7f08d29d28cf 0x7f08d29d37ba 0x7f08d2f8ed60 0x7f08d4b26279 0x7f08d274f530 0x7f08d2f3781c 0x7f08d301dbeb 0x7f08e25c9918 0x50a7f5 0x50c1f4 0x507f24 0x509202\n",
            "Evaluating: 100% 13/13 [2:13:35<00:00, 616.54s/it]\n",
            "10/28/2020 10:56:57 - INFO - __main__ -     Evaluation done in total 8015.065478 secs (38.533969 sec per example)\n",
            "10/28/2020 10:56:57 - INFO - transformers.data.metrics.squad_metrics -   Writing predictions to: ../prediction4/predictions_.json\n",
            "10/28/2020 10:56:57 - INFO - transformers.data.metrics.squad_metrics -   Writing nbest to: ../prediction4/nbest_predictions_.json\n",
            "10/28/2020 10:56:58 - INFO - __main__ -   Results: {'exact': 84.13461538461539, 'f1': 87.05929487179489, 'total': 208, 'HasAns_exact': 83.33333333333333, 'HasAns_f1': 89.67013888888887, 'HasAns_total': 96, 'NoAns_exact': 84.82142857142857, 'NoAns_f1': 84.82142857142857, 'NoAns_total': 112, 'best_exact': 88.9423076923077, 'best_exact_thresh': -8.306548953056335, 'best_f1': 91.06570512820511, 'best_f1_thresh': -5.363530158996582}\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     HasAns_exact = 83.33333333333333\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     HasAns_f1 = 89.67013888888887\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     HasAns_total = 96\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     NoAns_exact = 84.82142857142857\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     NoAns_f1 = 84.82142857142857\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     NoAns_total = 112\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     best_exact = 88.9423076923077\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     best_exact_thresh = -8.306548953056335\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     best_f1 = 91.06570512820511\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     best_f1_thresh = -5.363530158996582\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     exact = 84.13461538461539\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     f1 = 87.05929487179489\n",
            "10/28/2020 10:56:58 - INFO - __main__ -     total = 208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw1Oc39d0PGF",
        "outputId": "ea6d7f5b-4ab1-4ea3-98e7-ab80b24bc4cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "!tar -czvf prediction.tar.gz ../prediction4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar: Removing leading `../' from member names\n",
            "tar: ../prediction4: Cannot stat: No such file or directory\n",
            "tar: Exiting with failure status due to previous errors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaWS_TMTNY5b"
      },
      "source": [
        "# Downloading pretrained sketchy reader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heU-EQV8NeH2"
      },
      "source": [
        "Seemed like a bit of overhead for the demonstration in collge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaEW9LbbNnlT"
      },
      "source": [
        "## Download cls_model from codalab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLotK8BzPk83",
        "outputId": "8dc514a6-923b-4f73-e490-d2fa8b513000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!wget https://worksheets.codalab.org/rest/bundles/0x917cec21463744908e6fa5750ecaba73/contents/blob/ -O ../cls_model.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-30 09:03:44--  https://worksheets.codalab.org/rest/bundles/0x917cec21463744908e6fa5750ecaba73/contents/blob/\n",
            "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.114.41.203\n",
            "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.114.41.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Syntax error in Set-Cookie: codalab_session=\"\"; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=-1; Path=/ at position 70.\n",
            "Length: unspecified [application/gzip]\n",
            "Saving to: ‘../cls_model.tar.gz’\n",
            "\n",
            "../cls_model.tar.gz     [      <=>           ] 787.69M  15.9MB/s    in 49s     \n",
            "\n",
            "2020-09-30 09:04:34 (16.0 MB/s) - ‘../cls_model.tar.gz’ saved [825954288]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKHitClUNtVw"
      },
      "source": [
        "## Extract gipped tarball in `cls_model` directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "962SCRnANIlz"
      },
      "source": [
        "!mkdir ../cls_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMG6ZRzaQh2E",
        "outputId": "10611591-ae2e-4e48-b10c-2c5c44d42740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!tar -xvf ../cls_model.tar.gz -C ../cls_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./\n",
            "./spiece.model\n",
            "./pytorch_model.bin\n",
            "./config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLLKoWE0NzOE"
      },
      "source": [
        "# Run sketchy reader model on dev.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb7rKX6YQ4I9"
      },
      "source": [
        "!mkdir ../pred_cls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16SezuLcNKNL",
        "outputId": "0b73cd82-a5a0-402c-da63-992d28d891c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 -m examples.run_cls \\\n",
        "    --model_type albert \\\n",
        "    --model_name_or_path ../cls_model \\\n",
        "    --task_name squad \\\n",
        "    --do_predict \\\n",
        "    --do_lower_case \\\n",
        "    --predict_file ../dev-v2.0.json\\\n",
        "    --max_seq_length 512 \\\n",
        "    --per_gpu_eval_batch_size=16   \\\n",
        "    --output_dir ../pred_cls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-09-30 09:16:27.155267: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "09/30/2020 09:16:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "09/30/2020 09:16:28 - INFO - transformers.configuration_utils -   loading configuration file ../cls_model/config.json\n",
            "09/30/2020 09:16:28 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"finetuning_task\": \"squad\",\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "09/30/2020 09:16:28 - INFO - transformers.tokenization_utils -   Model name '../cls_model' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming '../cls_model' is a path or url to a directory containing tokenizer files.\n",
            "09/30/2020 09:16:28 - INFO - transformers.tokenization_utils -   Didn't find file ../cls_model/added_tokens.json. We won't load it.\n",
            "09/30/2020 09:16:28 - INFO - transformers.tokenization_utils -   Didn't find file ../cls_model/special_tokens_map.json. We won't load it.\n",
            "09/30/2020 09:16:28 - INFO - transformers.tokenization_utils -   Didn't find file ../cls_model/tokenizer_config.json. We won't load it.\n",
            "09/30/2020 09:16:28 - INFO - transformers.tokenization_utils -   loading file ../cls_model/spiece.model\n",
            "09/30/2020 09:16:28 - INFO - transformers.tokenization_utils -   loading file None\n",
            "09/30/2020 09:16:28 - INFO - transformers.tokenization_utils -   loading file None\n",
            "09/30/2020 09:16:28 - INFO - transformers.tokenization_utils -   loading file None\n",
            "09/30/2020 09:16:28 - INFO - transformers.modeling_utils -   loading weights file ../cls_model/pytorch_model.bin\n",
            "09/30/2020 09:16:41 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=False, do_lower_case=True, do_predict=True, do_train=False, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=512, max_steps=-1, model_name_or_path='../cls_model', model_type='albert', n_gpu=1, no_cuda=False, num_train_epochs=3.0, output_dir='../pred_cls', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=8, predict_file='../dev-v2.0.json', save_steps=50, seed=42, server_ip='', server_port='', task_name='squad', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
            "09/30/2020 09:16:41 - INFO - transformers.configuration_utils -   loading configuration file ../cls_model/config.json\n",
            "09/30/2020 09:16:41 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"finetuning_task\": \"squad\",\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "09/30/2020 09:16:41 - INFO - transformers.modeling_utils -   loading weights file ../cls_model/pytorch_model.bin\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   Writing example 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   guid: 56ddde6b9a695914005b9628\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   input_ids: 2 19 98 475 25 14650 335 60 3 14 4406 18 13 5 25388 45 90 911 177 43 18 73 484 45 4406 43 18 73 2068 45 4406 889 6 46 14 148 72 19 14 332 96 17 547 96 3113 492 66 204 20 14650 15 21 632 19 714 9 59 46 9581 37 16773 13 5 7 25388 7 1624 37 13 7 4747 18 12955 7 6 11341 17 8038 37 4913 15 10659 17 3796 72 15 131 66 1156 3001 111 15 1771 20 6688 3686 192 1084 20 437 922 1867 16 280 9612 4321 9 120 8163 16 28416 17 5826 29 14 1275 1556 1595 17 1171 8 12869 18491 8248 15 66 8568 83 5305 12666 29 14 6458 68 806 8 1281 9064 16 280 9612 4321 9 14 4421 1733 17 4206 3270 16 14 4406 18 5015 1537 19 14 64 519 16 14 332 96 428 15 17 32 578 20 19664 84 14 14843 3113 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   guid: 56ddde6b9a695914005b9629\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   input_ids: 2 76 46 14 4406 18 19 14650 60 3 14 4406 18 13 5 25388 45 90 911 177 43 18 73 484 45 4406 43 18 73 2068 45 4406 889 6 46 14 148 72 19 14 332 96 17 547 96 3113 492 66 204 20 14650 15 21 632 19 714 9 59 46 9581 37 16773 13 5 7 25388 7 1624 37 13 7 4747 18 12955 7 6 11341 17 8038 37 4913 15 10659 17 3796 72 15 131 66 1156 3001 111 15 1771 20 6688 3686 192 1084 20 437 922 1867 16 280 9612 4321 9 120 8163 16 28416 17 5826 29 14 1275 1556 1595 17 1171 8 12869 18491 8248 15 66 8568 83 5305 12666 29 14 6458 68 806 8 1281 9064 16 280 9612 4321 9 14 4421 1733 17 4206 3270 16 14 4406 18 5015 1537 19 14 64 519 16 14 332 96 428 15 17 32 578 20 19664 84 14 14843 3113 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   guid: 56ddde6b9a695914005b962a\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   input_ids: 2 37 56 1166 144 14 16773 24170 60 3 14 4406 18 13 5 25388 45 90 911 177 43 18 73 484 45 4406 43 18 73 2068 45 4406 889 6 46 14 148 72 19 14 332 96 17 547 96 3113 492 66 204 20 14650 15 21 632 19 714 9 59 46 9581 37 16773 13 5 7 25388 7 1624 37 13 7 4747 18 12955 7 6 11341 17 8038 37 4913 15 10659 17 3796 72 15 131 66 1156 3001 111 15 1771 20 6688 3686 192 1084 20 437 922 1867 16 280 9612 4321 9 120 8163 16 28416 17 5826 29 14 1275 1556 1595 17 1171 8 12869 18491 8248 15 66 8568 83 5305 12666 29 14 6458 68 806 8 1281 9064 16 280 9612 4321 9 14 4421 1733 17 4206 3270 16 14 4406 18 5015 1537 19 14 64 519 16 14 332 96 428 15 17 32 578 20 19664 84 14 14843 3113 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   guid: 56ddde6b9a695914005b962b\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   input_ids: 2 72 23 14 16773 1156 60 3 14 4406 18 13 5 25388 45 90 911 177 43 18 73 484 45 4406 43 18 73 2068 45 4406 889 6 46 14 148 72 19 14 332 96 17 547 96 3113 492 66 204 20 14650 15 21 632 19 714 9 59 46 9581 37 16773 13 5 7 25388 7 1624 37 13 7 4747 18 12955 7 6 11341 17 8038 37 4913 15 10659 17 3796 72 15 131 66 1156 3001 111 15 1771 20 6688 3686 192 1084 20 437 922 1867 16 280 9612 4321 9 120 8163 16 28416 17 5826 29 14 1275 1556 1595 17 1171 8 12869 18491 8248 15 66 8568 83 5305 12666 29 14 6458 68 806 8 1281 9064 16 280 9612 4321 9 14 4421 1733 17 4206 3270 16 14 4406 18 5015 1537 19 14 64 519 16 14 332 96 428 15 17 32 578 20 19664 84 14 14843 3113 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   guid: 56ddde6b9a695914005b962c\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   input_ids: 2 98 428 144 14 4406 18 64 3288 66 1725 3270 60 3 14 4406 18 13 5 25388 45 90 911 177 43 18 73 484 45 4406 43 18 73 2068 45 4406 889 6 46 14 148 72 19 14 332 96 17 547 96 3113 492 66 204 20 14650 15 21 632 19 714 9 59 46 9581 37 16773 13 5 7 25388 7 1624 37 13 7 4747 18 12955 7 6 11341 17 8038 37 4913 15 10659 17 3796 72 15 131 66 1156 3001 111 15 1771 20 6688 3686 192 1084 20 437 922 1867 16 280 9612 4321 9 120 8163 16 28416 17 5826 29 14 1275 1556 1595 17 1171 8 12869 18491 8248 15 66 8568 83 5305 12666 29 14 6458 68 806 8 1281 9064 16 280 9612 4321 9 14 4421 1733 17 4206 3270 16 14 4406 18 5015 1537 19 14 64 519 16 14 332 96 428 15 17 32 578 20 19664 84 14 14843 3113 9 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "09/30/2020 09:16:49 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "09/30/2020 09:16:49 - INFO - __main__ -   ***** Running evaluation *****\n",
            "09/30/2020 09:16:49 - INFO - __main__ -     Num examples = 208\n",
            "09/30/2020 09:16:49 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 13/13 [03:04<00:00, 14.19s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}