{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zhang Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "cItSLxjMr4BN",
        "hLoITfVnVAGc",
        "V8XuqKnAUNAq",
        "hlYNrTldspgj",
        "TEwrB5lCDLhK",
        "9HDgqRmgD7jE"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cItSLxjMr4BN"
      },
      "source": [
        "# Download our Code From [GitHub](https://github.com/rabinadk1/ReadIt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF8FBpBdz9RV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2af507-96b9-4484-baaf-e8867486b673"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK3uXEyhr88h"
      },
      "source": [
        "NOTE: Must include a download token since our repo is private"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLYkkQh-ddKG",
        "outputId": "c9079852-e389-4d3a-a586-12fb55e2b1ab"
      },
      "source": [
        "!wget https://codeload.github.com/rabinadk1/ReadIt/zip/master?token=AH4POJQMAG2DP5D2FXRMGDDAGPQEG -O ReadIt.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-22 16:43:55--  https://codeload.github.com/rabinadk1/ReadIt/zip/master?token=AH4POJQMAG2DP5D2FXRMGDDAGPQEG\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.113.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.113.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘ReadIt.zip’\n",
            "\n",
            "ReadIt.zip              [ <=>                ] 967.54K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-02-22 16:43:55 (41.6 MB/s) - ‘ReadIt.zip’ saved [990759]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIXTRamosHA4"
      },
      "source": [
        "Unzip the downloaded file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTKmwLR-eYtP",
        "outputId": "c9b9ce9b-9395-4d58-b5f9-70d15c9d1bfd"
      },
      "source": [
        "!unzip ReadIt.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ReadIt.zip\n",
            "8d894c4c44ae516b1578a04e3c78608dc4521800\n",
            "   creating: ReadIt-master/\n",
            "  inflating: ReadIt-master/.gitignore  \n",
            "   creating: ReadIt-master/.vscode/\n",
            " extracting: ReadIt-master/.vscode/settings.json  \n",
            "  inflating: ReadIt-master/README.md  \n",
            "  inflating: ReadIt-master/dev-v2.0'.json  \n",
            "  inflating: ReadIt-master/dev-v2.0.json  \n",
            "  inflating: ReadIt-master/dev-v2.0modified.json  \n",
            "  inflating: ReadIt-master/devFormat.py  \n",
            "  inflating: ReadIt-master/evaluate_official2.py  \n",
            "   creating: ReadIt-master/mrc/\n",
            "  inflating: ReadIt-master/mrc/__init__.py  \n",
            "  inflating: ReadIt-master/mrc/routes.py  \n",
            "   creating: ReadIt-master/notebooks/\n",
            "  inflating: ReadIt-master/notebooks/ReadIT.ipynb  \n",
            "  inflating: ReadIt-master/notebooks/Zhang_Test.ipynb  \n",
            "  inflating: ReadIt-master/prediction.sh  \n",
            " extracting: ReadIt-master/requirements.txt  \n",
            "  inflating: ReadIt-master/result.txt  \n",
            "  inflating: ReadIt-master/run.sh    \n",
            "  inflating: ReadIt-master/run_base.py  \n",
            "  inflating: ReadIt-master/run_cls.py  \n",
            "  inflating: ReadIt-master/run_squad.py  \n",
            "  inflating: ReadIt-master/setup.cfg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODVSKQjmsKNF"
      },
      "source": [
        "Change directory permanently to our project root"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDWH4UF0uXmB",
        "outputId": "59d3a080-f29d-4510-cae0-504bd73dc321"
      },
      "source": [
        "%cd /content/ReadIt-master/\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ReadIt-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyM0HqoMsPqx"
      },
      "source": [
        "Install required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TboKNULSgJbg",
        "outputId": "49bcbad1-6374-4fd7-91ae-161763e98e2b"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\r\u001b[K     |▊                               | 10kB 26.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 30.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 21.0MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 24.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 25.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 28.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 18.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 20.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 18.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 18.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 18.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 122kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 18.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 174kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 194kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 18.2MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 225kB 18.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 245kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 18.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 296kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 317kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 18.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 337kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 348kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 368kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 389kB 18.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 399kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 409kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 440kB 18.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask==1.1.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.1.2)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 20.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/53/001f30958e799a1635dfd062f94af2b16b836fc4366ff231fe2f2c7c8b50/boto3-1.17.12-py2.py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 62.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.2->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.2->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.2->-r requirements.txt (line 2)) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask==1.1.2->-r requirements.txt (line 2)) (1.0.1)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.9MB/s \n",
            "\u001b[?25hCollecting botocore<1.21.0,>=1.20.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/78/b71baa2fa2dac70638a360ec6fdb00960134a1b68e895acc12b8f6916da2/botocore-1.20.12-py2.py3-none-any.whl (7.2MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2MB 50.6MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->-r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask==1.1.2->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.21.0,>=1.20.12->boto3->transformers==2.3.0->-r requirements.txt (line 1)) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=da7936d665098e5e59b23e60ccf22f5f39bf1cb468b454e6df1369f353872d03\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Successfully installed boto3-1.17.12 botocore-1.20.12 jmespath-0.10.0 s3transfer-0.3.4 sacremoses-0.0.43 sentencepiece-0.1.95 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsRMceRisg-L"
      },
      "source": [
        "# Download the model4 from codalab (Deprecated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEaD-EAwUXlJ"
      },
      "source": [
        "Run only if there is no model in google drive. Warning: **It may take extremely long time to download**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSx8CQQ9tMP2"
      },
      "source": [
        "The model is of size 787.72M . Normally it takes may take around 1m 43s to download."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Cb5ZoCrqUzj",
        "outputId": "bb3ad293-7eb0-4e49-b2ac-6313afebbffd"
      },
      "source": [
        "!wget https://worksheets.codalab.org/rest/bundles/0x6ac39bac7de2473eb13f737ce4657c56/contents/blob/ -O model4.tar.gz"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-22 16:55:56--  https://worksheets.codalab.org/rest/bundles/0x6ac39bac7de2473eb13f737ce4657c56/contents/blob/\n",
            "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.114.41.203\n",
            "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.114.41.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Syntax error in Set-Cookie: codalab_session=\"\"; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=-1; Path=/ at position 70.\n",
            "Length: unspecified [application/gzip]\n",
            "Saving to: ‘model4.tar.gz’\n",
            "\n",
            "model4.tar.gz           [                <=> ] 787.72M  14.7MB/s    in 51s     \n",
            "\n",
            "2021-02-22 16:56:48 (15.3 MB/s) - ‘model4.tar.gz’ saved [825983721]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iShuKDhkXflX"
      },
      "source": [
        "### Run only after mouting the google drive in the following Heading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjj97M48VDxW"
      },
      "source": [
        "Change working directory to `/gdrive/My\\ Drive` to make copying easier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04venvCYU04X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390174ce-c6e5-4b57-9781-319db5bfe4cc"
      },
      "source": [
        "%cd /gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/gdrive/My Drive'\n",
            "/content/ReadIt-predict_test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g18DLtQVW-gt"
      },
      "source": [
        "Make a directory if not already"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIS5DtlgXBI_"
      },
      "source": [
        "!mkdir ReadIt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1PgCDp-XJbT"
      },
      "source": [
        "Copy the downloaded model to Google Drive for further use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR3puy13XHnS"
      },
      "source": [
        "!cp /content/ReadIt-master/model4.tar.gz ReadIt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFlg2CLzU8QJ"
      },
      "source": [
        "Change working directory back to project root"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYcDf0ktU7WR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03187cb3-6984-44b6-eb6a-b129f53022d9"
      },
      "source": [
        "%cd /content/ReadIt-master/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ReadIt-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLoITfVnVAGc"
      },
      "source": [
        "\n",
        "# Mount google drive at `/gdrive`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMcjq_qhT81I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425757d2-ac5b-4d46-c172-2bddf6a4369b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8XuqKnAUNAq"
      },
      "source": [
        "# Copy model from Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm5gqyX8VTtr"
      },
      "source": [
        "Copy from drive to project root"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WwsQUQ_VpiR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab855962-fcbb-4bb6-8140-b4cf9229222f"
      },
      "source": [
        "!cp /gdrive/My\\ Drive/ReadIt/model4.tar.gz /content/ReadIt-master/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/gdrive/My Drive/ReadIt/model4.tar.gz': Transport endpoint is not connected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlYNrTldspgj"
      },
      "source": [
        "# Make directory for model extract and extract it there"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIpeQhTOqpmi"
      },
      "source": [
        "!mkdir model4"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvzDHGl6q3MH",
        "outputId": "05f0f786-6cee-4ff4-fb7a-b63513f15995"
      },
      "source": [
        "!tar -xvf model4.tar.gz -C model4"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./\n",
            "./config.json\n",
            "./pytorch_model.bin\n",
            "./spiece.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rLF_hEfrN9c",
        "outputId": "49db00fa-e9a7-47e4-c593-74c4c9add002"
      },
      "source": [
        "# mkdir prediction4\n",
        "!pwd"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ReadIt-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CwYgJLu-6C6"
      },
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEwrB5lCDLhK"
      },
      "source": [
        "# Training\n",
        "Download squad 2.0 train dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl6SRdh04hsr"
      },
      "source": [
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json -o train-v2.0.json"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t_Rd3y3DoKs"
      },
      "source": [
        "Run training script with required args. `fp16 training requires nvdia-apex `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHC8n2mq3uSZ",
        "outputId": "ddf1425d-2db0-4a20-dafb-1ecbe29130ce"
      },
      "source": [
        "!python3 run_squad.py \\\n",
        "    --model_type albert \\\n",
        "    --model_name_or_path albert-xxlarge-v2 \\\n",
        "    --do_train \\\n",
        "    --do_lower_case \\\n",
        "    --version_2_with_negative \\\n",
        "    --train_file ./train-v2.0.json \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 2 \\\n",
        "    --max_seq_length 512 \\\n",
        "    --doc_stride 128 \\\n",
        "    --max_query_length=64 \\\n",
        "    --per_gpu_train_batch_size=6 \\\n",
        "    --warmup_steps=814 \\\n",
        "    --output_dir ./model1 \\\n",
        "    --eval_all_checkpoints \\\n",
        "    --save_steps 2500 \\\n",
        "    --n_best_size=20 \\\n",
        "    --max_answer_length=30 \\\n",
        "    # --fp16"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-22 18:39:55.475034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "02/22/2021 18:39:57 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: True\n",
            "02/22/2021 18:39:57 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/albert-xxlarge-v2-config.json from cache at /root/.cache/torch/transformers/b3eed512e24335a76694282193217608ead013caa55330de3ff236d1f5695e6c.969ffb8d07aebbe39c189cbb0576be382e85f6960fcc4aec32eb97cd44be53a2\n",
            "02/22/2021 18:39:57 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"AlbertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu_new\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "02/22/2021 18:39:57 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/albert-xxlarge-v2-spiece.model from cache at /root/.cache/torch/transformers/094b3b4d4ab5e624ae6ba8654d88cdb99b2d5a813b323295c37d58680a1c4127.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf\n",
            "02/22/2021 18:39:57 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/albert-xxlarge-v2-pytorch_model.bin from cache at /root/.cache/torch/transformers/c8f990f22da3ddf461b7e0d30a079014b20ad2859f352a9f18421485f63a69e7.9ac42d6fae7d18840d74eaf2a6d817700ffdd5af9ae1a12c3e96e239e23f76f4\n",
            "02/22/2021 18:40:04 - INFO - transformers.modeling_utils -   Weights of AlbertForQuestionAnswering not initialized from pretrained model: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "02/22/2021 18:40:04 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in AlbertForQuestionAnswering: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
            "02/22/2021 18:40:08 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='', device=device(type='cuda'), do_eval=False, do_lower_case=True, do_train=True, doc_stride=128, eval_all_checkpoints=True, evaluate_during_training=False, fp16=True, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=512, max_steps=-1, model_name_or_path='albert-xxlarge-v2', model_type='albert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=2.0, output_dir='./model1', overwrite_cache=False, overwrite_output_dir=False, padding_side='right', per_gpu_eval_batch_size=8, per_gpu_train_batch_size=6, predict_file=None, save_steps=2500, seed=42, server_ip='', server_port='', tokenizer_name='', train_file='./train-v2.0.json', verbose_logging=False, version_2_with_negative=True, warmup_steps=814, weight_decay=0.0)\n",
            "Traceback (most recent call last):\n",
            "  File \"run_squad.py\", line 564, in main\n",
            "    import apex\n",
            "ModuleNotFoundError: No module named 'apex'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"run_squad.py\", line 674, in <module>\n",
            "    main()\n",
            "  File \"run_squad.py\", line 568, in main\n",
            "    \"Please install apex from \"\n",
            "ImportError: Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HDgqRmgD7jE"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjbSEGoYpFtT",
        "outputId": "93a0c1dd-ec07-4d51-8e20-ef0129793a6b"
      },
      "source": [
        "!python3 run_squad.py \\\n",
        "    --model_type albert \\\n",
        "    --model_name_or_path ./model4 \\\n",
        "    --do_eval \\\n",
        "    --do_lower_case \\\n",
        "    --version_2_with_negative \\\n",
        "    --predict_file ./dev-v2.0modified.json \\\n",
        "    --max_seq_length 512 \\\n",
        "    --n_best_size=20 \\\n",
        "    --max_answer_length=30 \\\n",
        "    --doc_stride 128 \\\n",
        "    --max_query_length=64 \\\n",
        "    --per_gpu_eval_batch_size=16 \\\n",
        "    --output_dir ../prediction4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-16 14:39:58.631240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "02/16/2021 14:40:00 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "02/16/2021 14:40:00 - INFO - transformers.configuration_utils -   loading configuration file ./model4/config.json\n",
            "02/16/2021 14:40:00 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "02/16/2021 14:40:00 - INFO - transformers.tokenization_utils -   Model name './model4' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming './model4' is a path or url to a directory containing tokenizer files.\n",
            "02/16/2021 14:40:00 - INFO - transformers.tokenization_utils -   Didn't find file ./model4/added_tokens.json. We won't load it.\n",
            "02/16/2021 14:40:00 - INFO - transformers.tokenization_utils -   Didn't find file ./model4/special_tokens_map.json. We won't load it.\n",
            "02/16/2021 14:40:00 - INFO - transformers.tokenization_utils -   Didn't find file ./model4/tokenizer_config.json. We won't load it.\n",
            "02/16/2021 14:40:00 - INFO - transformers.tokenization_utils -   loading file ./model4/spiece.model\n",
            "02/16/2021 14:40:00 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/16/2021 14:40:00 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/16/2021 14:40:00 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/16/2021 14:40:00 - INFO - transformers.modeling_utils -   loading weights file ./model4/pytorch_model.bin\n",
            "02/16/2021 14:40:10 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in AlbertForQuestionAnswering: ['has_ans.1.weight', 'has_ans.1.bias']\n",
            "02/16/2021 14:40:13 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, doc_stride=128, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=512, max_steps=-1, model_name_or_path='./model4', model_type='albert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='../prediction4', overwrite_cache=False, overwrite_output_dir=False, padding_side='right', per_gpu_eval_batch_size=16, per_gpu_train_batch_size=8, predict_file='./dev-v2.0modified.json', save_steps=50, seed=42, server_ip='', server_port='', tokenizer_name='', train_file=None, verbose_logging=False, version_2_with_negative=True, warmup_steps=0, weight_decay=0.0)\n",
            "02/16/2021 14:40:13 - INFO - __main__ -   Loading checkpoint ./model4 for evaluation\n",
            "02/16/2021 14:40:13 - INFO - __main__ -   Evaluate the following checkpoints: ['./model4']\n",
            "02/16/2021 14:40:13 - INFO - transformers.configuration_utils -   loading configuration file ./model4/config.json\n",
            "02/16/2021 14:40:13 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "02/16/2021 14:40:13 - INFO - transformers.modeling_utils -   loading weights file ./model4/pytorch_model.bin\n",
            "02/16/2021 14:40:23 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in AlbertForQuestionAnswering: ['has_ans.1.weight', 'has_ans.1.bias']\n",
            "02/16/2021 14:40:23 - INFO - __main__ -   Creating features from dataset file at .\n",
            "100% 1/1 [00:00<00:00, 1102.31it/s]\n",
            "Converting examples to features: 100% 2/2 [00:00<00:00, 131.52it/s]\n",
            "02/16/2021 14:40:23 - INFO - __main__ -   Saving features into cached file ./cached_dev_model4_512\n",
            "Examples:  [<transformers.data.processors.squad.SquadExample object at 0x7fe8f1ebe358>, <transformers.data.processors.squad.SquadExample object at 0x7fe8f1ebe278>]\n",
            "\n",
            "\n",
            "02/16/2021 14:40:23 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "02/16/2021 14:40:23 - INFO - __main__ -     Num examples = 2\n",
            "02/16/2021 14:40:23 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 1/1 [00:02<00:00,  2.71s/it]\n",
            "02/16/2021 14:40:25 - INFO - __main__ -     Evaluation done in total 2.7087360389998594 secs (1.3543680194999297 sec per example)\n",
            "OrderedDict([('56ddde6b9a695914005b9628', 'a group of words put together to form a group that is usually longer than a sentence.'), ('5ad39d53604f3c001a3fe8d4', 'In most organized forms of writing, such as essays,')])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8OlCEcPALxl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}