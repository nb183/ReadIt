{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zhang Test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LNgO75uFsUPC"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cItSLxjMr4BN"
      },
      "source": [
        "# Download our Code From Github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK3uXEyhr88h"
      },
      "source": [
        "NOTE: Must include a download token since our repo is private"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLYkkQh-ddKG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c8adc7f-c178-4b21-99b7-9483ad3a5929"
      },
      "source": [
        "!wget https://codeload.github.com/rabinadk1/ReadIt/zip/master?token=AHULVOLIE5G5B7BO23BOTY27YECQS -O ReadIt.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-27 13:50:02--  https://codeload.github.com/rabinadk1/ReadIt/zip/master?token=AHULVOLIE5G5B7BO23BOTY27YECQS\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘ReadIt.zip’\n",
            "\n",
            "ReadIt.zip              [ <=>                ]  52.96K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-11-27 13:50:03 (1007 KB/s) - ‘ReadIt.zip’ saved [54232]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIXTRamosHA4"
      },
      "source": [
        "Unzip the downloaded file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTKmwLR-eYtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c67de3d-a64e-4e24-933d-5af6bd478a82"
      },
      "source": [
        "!unzip ReadIt.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ReadIt.zip\n",
            "942c2a513bbb82c3fe32d06a6260d4b1360889ff\n",
            "   creating: ReadIt-master/\n",
            "  inflating: ReadIt-master/.gitignore  \n",
            "   creating: ReadIt-master/.vscode/\n",
            " extracting: ReadIt-master/.vscode/settings.json  \n",
            "  inflating: ReadIt-master/ReadIT.ipynb  \n",
            "  inflating: ReadIt-master/dev-v2.0.json  \n",
            "  inflating: ReadIt-master/evaluate_official2.py  \n",
            " extracting: ReadIt-master/requirements.txt  \n",
            "  inflating: ReadIt-master/result.txt  \n",
            "  inflating: ReadIt-master/run_cls.py  \n",
            "  inflating: ReadIt-master/run_squad.py  \n",
            "  inflating: ReadIt-master/setup.cfg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODVSKQjmsKNF"
      },
      "source": [
        "Change directory permanently to our project root"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDWH4UF0uXmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648522e4-1236-4ea5-b3e8-8fc8bdd5e550"
      },
      "source": [
        "%cd ReadIt-master/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ReadIt-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyM0HqoMsPqx"
      },
      "source": [
        "Install required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TboKNULSgJbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cd2a876-dee1-4324-920c-98ffc9aa9f72"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\r\u001b[K     |▊                               | 10kB 20.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 19.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 11.8MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 9.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 122kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 174kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 194kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 225kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 245kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 296kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 317kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 337kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 348kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 368kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 389kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 399kB 7.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 409kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 440kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 45.5MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/7f/4ade91fbb684c6f28a6e56028d9f9d2de4297761850d083579779f07c0de/boto3-1.16.25-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 52.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.3.0->-r requirements.txt (line 1)) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 1)) (2020.11.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->-r requirements.txt (line 1)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.3.0->-r requirements.txt (line 1)) (0.17.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.20.0,>=1.19.25\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/d5/c0c33ca15e31062220ac5964f3492409eaf90a5cf5399503cd8264f2f8e9/botocore-1.19.25-py2.py3-none-any.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 52.8MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.25->boto3->transformers==2.3.0->-r requirements.txt (line 1)) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=b385f4d417e6e2ac3fdf3f0336c15f150401de3d9a98185133b6b06764e2e63a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: botocore 1.19.25 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sacremoses, jmespath, botocore, s3transfer, boto3, sentencepiece, transformers\n",
            "Successfully installed boto3-1.16.25 botocore-1.19.25 jmespath-0.10.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 transformers-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNgO75uFsUPC"
      },
      "source": [
        "# Old AwesomeMRC Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E8eomsYsXgi"
      },
      "source": [
        "Should not be run unless you're sure of what you're doing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52Wn8Qbhmhvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19c3e3b5-7d7f-4f82-858b-03b0d1820071"
      },
      "source": [
        "!wget https://codeload.github.com/cooelf/AwesomeMRC/zip/master -O master.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-26 04:26:26--  https://codeload.github.com/cooelf/AwesomeMRC/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 52.193.111.178\n",
            "Connecting to codeload.github.com (codeload.github.com)|52.193.111.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [  <=>               ]   2.54M  9.63MB/s    in 0.3s    \n",
            "\n",
            "2020-11-26 04:26:27 (9.63 MB/s) - ‘master.zip’ saved [2667359]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TW2rNF3vSpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a384d806-000a-42d6-d660-aac790021a32"
      },
      "source": [
        "!unzip master.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  master.zip\n",
            "9ff6dfe3c183d7ae8c7ad46ae88e19bf2c352098\n",
            "   creating: AwesomeMRC-master/\n",
            "  inflating: AwesomeMRC-master/.gitignore  \n",
            "  inflating: AwesomeMRC-master/README.md  \n",
            "   creating: AwesomeMRC-master/figures/\n",
            "  inflating: AwesomeMRC-master/figures/clm_examples.png  \n",
            "  inflating: AwesomeMRC-master/figures/overview.png  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/\n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/benchmarks.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/contrib/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/contrib/README.md  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/contrib/run_camembert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/contrib/run_openai_gpt.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/contrib/run_swag.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/contrib/run_transfo_xl.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/distillation/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/README.md  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/distiller.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/grouped_batch_sampler.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/lm_seqs_dataset.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/requirements.txt  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/run_squad_w_distillation.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/distillation/scripts/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/scripts/binarized_data.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/scripts/extract.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/scripts/extract_distilbert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/scripts/token_counts.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/train.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/distillation/training_configs/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/training_configs/distilbert-base-uncased.json  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/training_configs/distilgpt2.json  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/distillation/utils.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/evaluate_official2.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/pplm/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/pplm/README.md  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/pplm/imgs/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/pplm/imgs/headfigure.png  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/pplm/imgs/wooly.png  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/pplm/pplm_classification_head.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/pplm/run_pplm.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/pplm/run_pplm_discrim_train.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/requirements.txt  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/run_bertology.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/run_cls.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/run_squad.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/run_squad_av.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/run_squad_av_all.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/run_squad_av_bce.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/run_squad_avreg.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/run_squad_dep.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/run_squad_seq_sc.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/run_squad_seq_trm.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/run_verifier.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/runs/\n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/runs/May14_17-05-20_LAPTOP-35F8BIJU/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/runs/May14_17-05-20_LAPTOP-35F8BIJU/events.out.tfevents.1589443520.LAPTOP-35F8BIJU.17892.0  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/summarization/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/summarization/README.md  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/summarization/configuration_bertabs.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/summarization/convert_bertabs_original_pytorch_checkpoint.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/summarization/modeling_bertabs.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/summarization/requirements.txt  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/summarization/run_summarization.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/summarization/utils_summarization.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/summarization/utils_summarization_test.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/tests_samples/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/tests_samples/.gitignore  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/tests_samples/MRPC/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/tests_samples/MRPC/dev.tsv  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/tests_samples/MRPC/train.tsv  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/examples/tests_samples/SQUAD/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/tests_samples/SQUAD/dev-v2.0.json  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/tests_samples/SQUAD/train-v2.0.json  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/utils_multiple_choice.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/examples/utils_ner.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/sh_albert_av.sh  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/sh_albert_cls.sh  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/sh_albert_seq_trm.sh  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/transformers/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/__init__.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/__main__.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/transformers/commands/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/commands/__init__.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/commands/convert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/commands/download.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/commands/run.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/commands/serving.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/commands/train.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/commands/user.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_albert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_auto.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_bert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_camembert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_ctrl.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_distilbert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_gpt2.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_openai.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_roberta.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_t5.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_transfo_xl.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_utils.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_xlm.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_xlm_roberta.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/configuration_xlnet.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/convert_albert_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/convert_bert_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/convert_bert_pytorch_checkpoint_to_original_tf.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/convert_gpt2_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/convert_openai_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/convert_pytorch_checkpoint_to_tf2.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/convert_roberta_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/convert_t5_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/convert_xlm_original_pytorch_checkpoint_to_pytorch.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/convert_xlnet_original_tf_checkpoint_to_pytorch.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/transformers/data/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/data/__init__.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/transformers/data/metrics/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/data/metrics/__init__.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/data/metrics/squad_metrics.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/transformers/data/processors/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/data/processors/__init__.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/data/processors/glue.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/data/processors/squad.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/data/processors/utils.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/data/processors/xnli.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/file_utils.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/hf_api.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modelcard.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_albert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_auto.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_bert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_camembert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_ctrl.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_distilbert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_encoder_decoder.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_gpt2.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_openai.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_roberta.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_t5.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_albert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_auto.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_bert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_ctrl.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_distilbert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_gpt2.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_openai.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_pytorch_utils.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_roberta.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_t5.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_transfo_xl.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_transfo_xl_utilities.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_utils.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_xlm.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_tf_xlnet.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_transfo_xl.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_transfo_xl_utilities.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_utils.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_xlm.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_xlm_roberta.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/modeling_xlnet.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/optimization.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/optimization_tf.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/pipelines.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/transformers/tests/\n",
            " extracting: AwesomeMRC-master/transformer-mrc/transformers/tests/__init__.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/configuration_common_test.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/transformers/tests/fixtures/\n",
            " extracting: AwesomeMRC-master/transformer-mrc/transformers/tests/fixtures/empty.txt  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/fixtures/input.txt  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/fixtures/sample_text.txt  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/fixtures/spiece.model  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/fixtures/test_sentencepiece.model  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/hf_api_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/model_card_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_albert_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_auto_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_bert_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_common_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_ctrl_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_distilbert_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_encoder_decoder_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_gpt2_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_openai_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_roberta_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_t5_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_albert_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_auto_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_bert_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_common_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_ctrl_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_distilbert_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_gpt2_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_openai_gpt_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_roberta_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_t5_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_transfo_xl_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_xlm_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_tf_xlnet_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_transfo_xl_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_xlm_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/modeling_xlnet_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/optimization_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/optimization_tf_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/pipelines_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_albert_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_auto_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_bert_japanese_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_bert_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_ctrl_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_distilbert_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_gpt2_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_openai_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_roberta_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_t5_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_tests_commons.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_transfo_xl_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_utils_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_xlm_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/tokenization_xlnet_test.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tests/utils.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_albert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_auto.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_bert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_bert_japanese.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_camembert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_ctrl.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_distilbert.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_gpt2.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_openai.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_roberta.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_t5.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_transfo_xl.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_utils.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_xlm.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_xlm_roberta.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/transformers/tokenization_xlnet.py  \n",
            "   creating: AwesomeMRC-master/transformer-mrc/utils/\n",
            "  inflating: AwesomeMRC-master/transformer-mrc/utils/download_glue_data.py  \n",
            "  inflating: AwesomeMRC-master/transformer-mrc/utils/link_tester.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkw1V8N2o_qy"
      },
      "source": [
        "!mv master/transformer-mrc/transformers trim/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu6ZosDlv52N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc85a675-0f6a-4069-bb84-1485ac278077"
      },
      "source": [
        "%cd trim/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/trim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsRMceRisg-L"
      },
      "source": [
        "# Download the model4 from codalab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSx8CQQ9tMP2"
      },
      "source": [
        "The model is of size 787.72M it takes may take time around 1m 43s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cb5ZoCrqUzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04e13c13-2501-474c-d5bd-e204dbec260d"
      },
      "source": [
        "!wget https://worksheets.codalab.org/rest/bundles/0x6ac39bac7de2473eb13f737ce4657c56/contents/blob/ -O model4.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-27 13:50:45--  https://worksheets.codalab.org/rest/bundles/0x6ac39bac7de2473eb13f737ce4657c56/contents/blob/\n",
            "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.114.41.203\n",
            "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.114.41.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Syntax error in Set-Cookie: codalab_session=\"\"; expires=Thu, 01 Jan 1970 00:00:00 GMT; Max-Age=-1; Path=/ at position 70.\n",
            "Length: unspecified [application/gzip]\n",
            "Saving to: ‘model4.tar.gz’\n",
            "\n",
            "model4.tar.gz           [           <=>      ] 787.72M  14.0MB/s    in 52s     \n",
            "\n",
            "2020-11-27 13:51:38 (15.0 MB/s) - ‘model4.tar.gz’ saved [825983721]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlYNrTldspgj"
      },
      "source": [
        "# Make directory for model extract and extract it there"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIpeQhTOqpmi"
      },
      "source": [
        "!mkdir model4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvzDHGl6q3MH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65ebfde-52d0-42b8-ac51-895e72e6d694"
      },
      "source": [
        "!tar -xvf model4.tar.gz -C model4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./\n",
            "./config.json\n",
            "./pytorch_model.bin\n",
            "./spiece.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rLF_hEfrN9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14364978-f10d-4dbd-881b-59f8bc4b828c"
      },
      "source": [
        "# mkdir prediction4\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ReadIt-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CwYgJLu-6C6"
      },
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjbSEGoYpFtT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49667889-c47b-4018-dfff-3a0977536a00"
      },
      "source": [
        "!python3 run_squad.py \\\n",
        "    --model_type albert \\\n",
        "    --model_name_or_path ./model4 \\\n",
        "    --do_eval \\\n",
        "    --do_lower_case \\\n",
        "    --version_2_with_negative \\\n",
        "    --predict_file ./dev-v2.0.json \\\n",
        "    --max_seq_length 512 \\\n",
        "    --n_best_size=20 \\\n",
        "    --max_answer_length=30 \\\n",
        "    --doc_stride 128 \\\n",
        "    --max_query_length=64 \\\n",
        "    --per_gpu_eval_batch_size=16 \\\n",
        "    --output_dir ../prediction4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-27 14:12:28.967662: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/27/2020 14:12:30 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "11/27/2020 14:12:30 - INFO - transformers.configuration_utils -   loading configuration file ./model4/config.json\n",
            "11/27/2020 14:12:30 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "11/27/2020 14:12:30 - INFO - transformers.tokenization_utils -   Model name './model4' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming './model4' is a path or url to a directory containing tokenizer files.\n",
            "11/27/2020 14:12:30 - INFO - transformers.tokenization_utils -   Didn't find file ./model4/added_tokens.json. We won't load it.\n",
            "11/27/2020 14:12:30 - INFO - transformers.tokenization_utils -   Didn't find file ./model4/special_tokens_map.json. We won't load it.\n",
            "11/27/2020 14:12:30 - INFO - transformers.tokenization_utils -   Didn't find file ./model4/tokenizer_config.json. We won't load it.\n",
            "11/27/2020 14:12:30 - INFO - transformers.tokenization_utils -   loading file ./model4/spiece.model\n",
            "11/27/2020 14:12:30 - INFO - transformers.tokenization_utils -   loading file None\n",
            "11/27/2020 14:12:30 - INFO - transformers.tokenization_utils -   loading file None\n",
            "11/27/2020 14:12:30 - INFO - transformers.tokenization_utils -   loading file None\n",
            "11/27/2020 14:12:30 - INFO - transformers.modeling_utils -   loading weights file ./model4/pytorch_model.bin\n",
            "11/27/2020 14:12:39 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in AlbertForQuestionAnswering: ['has_ans.1.weight', 'has_ans.1.bias']\n",
            "11/27/2020 14:12:43 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, doc_stride=128, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, local_rank=-1, logging_steps=50, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=512, max_steps=-1, model_name_or_path='./model4', model_type='albert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='../prediction4', overwrite_cache=False, overwrite_output_dir=False, padding_side='right', per_gpu_eval_batch_size=16, per_gpu_train_batch_size=8, predict_file='./dev-v2.0.json', save_steps=50, seed=42, server_ip='', server_port='', tokenizer_name='', train_file=None, verbose_logging=False, version_2_with_negative=True, warmup_steps=0, weight_decay=0.0)\n",
            "11/27/2020 14:12:43 - INFO - __main__ -   Loading checkpoint ./model4 for evaluation\n",
            "11/27/2020 14:12:43 - INFO - __main__ -   Evaluate the following checkpoints: ['./model4']\n",
            "11/27/2020 14:12:43 - INFO - transformers.configuration_utils -   loading configuration file ./model4/config.json\n",
            "11/27/2020 14:12:43 - INFO - transformers.configuration_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "11/27/2020 14:12:43 - INFO - transformers.modeling_utils -   loading weights file ./model4/pytorch_model.bin\n",
            "11/27/2020 14:12:52 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in AlbertForQuestionAnswering: ['has_ans.1.weight', 'has_ans.1.bias']\n",
            "Reason for not being loaded from cache:  ./cached_dev_model4_512 True False\n",
            "11/27/2020 14:12:52 - INFO - __main__ -   Creating features from dataset file at .\n",
            "100% 1/1 [00:00<00:00, 16.85it/s]\n",
            "Converting examples to features: 100% 208/208 [00:01<00:00, 192.51it/s]\n",
            "11/27/2020 14:12:53 - INFO - __main__ -   Saving features into cached file ./cached_dev_model4_512\n",
            "11/27/2020 14:12:53 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "11/27/2020 14:12:53 - INFO - __main__ -     Num examples = 208\n",
            "11/27/2020 14:12:53 - INFO - __main__ -     Batch size = 16\n",
            "Evaluating: 100% 13/13 [03:05<00:00, 14.30s/it]\n",
            "11/27/2020 14:15:59 - INFO - __main__ -     Evaluation done in total 185.94446482500007 secs (0.8939637731971157 sec per example)\n",
            "11/27/2020 14:15:59 - INFO - transformers.data.metrics.squad_metrics -   Writing predictions to: ../prediction4/predictions_.json\n",
            "11/27/2020 14:15:59 - INFO - transformers.data.metrics.squad_metrics -   Writing nbest to: ../prediction4/nbest_predictions_.json\n",
            "11/27/2020 14:16:00 - INFO - __main__ -   Results: {'exact': 84.13461538461539, 'f1': 87.05929487179489, 'total': 208, 'HasAns_exact': 83.33333333333333, 'HasAns_f1': 89.67013888888887, 'HasAns_total': 96, 'NoAns_exact': 84.82142857142857, 'NoAns_f1': 84.82142857142857, 'NoAns_total': 112, 'best_exact': 88.9423076923077, 'best_exact_thresh': -8.306549906730652, 'best_f1': 91.06570512820511, 'best_f1_thresh': -5.3635125160217285}\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     HasAns_exact = 83.33333333333333\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     HasAns_f1 = 89.67013888888887\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     HasAns_total = 96\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     NoAns_exact = 84.82142857142857\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     NoAns_f1 = 84.82142857142857\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     NoAns_total = 112\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     best_exact = 88.9423076923077\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     best_exact_thresh = -8.306549906730652\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     best_f1 = 91.06570512820511\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     best_f1_thresh = -5.3635125160217285\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     exact = 84.13461538461539\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     f1 = 87.05929487179489\n",
            "11/27/2020 14:16:00 - INFO - __main__ -     total = 208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to5Brf8OugZy"
      },
      "source": [
        "## New code for new transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJBhZvtbxa0U"
      },
      "source": [
        "**Currently Not working**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX-yRxy6vsQ1",
        "outputId": "e8a8ff99-9f96-454d-99ef-e070dbf31396"
      },
      "source": [
        "!pip3 install -U transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.51.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Installing collected packages: sentencepiece, tokenizers, transformers\n",
            "  Found existing installation: sentencepiece 0.1.94\n",
            "    Uninstalling sentencepiece-0.1.94:\n",
            "      Successfully uninstalled sentencepiece-0.1.94\n",
            "  Found existing installation: tokenizers 0.7.0\n",
            "    Uninstalling tokenizers-0.7.0:\n",
            "      Successfully uninstalled tokenizers-0.7.0\n",
            "  Found existing installation: transformers 2.3.0\n",
            "    Uninstalling transformers-2.3.0:\n",
            "      Successfully uninstalled transformers-2.3.0\n",
            "Successfully installed sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtI_Ea2rv6mU",
        "outputId": "9c130162-5d63-4eaa-bdcb-48973afecc5a"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/run_squad.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-27 12:48:48--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/run_squad.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34740 (34K) [text/plain]\n",
            "Saving to: ‘run_squad.py.1’\n",
            "\n",
            "run_squad.py.1      100%[===================>]  33.93K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-11-27 12:48:49 (24.3 MB/s) - ‘run_squad.py.1’ saved [34740/34740]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpI635ret-w9",
        "outputId": "ae7d606c-9ef7-440e-da23-4769f47ca3d3"
      },
      "source": [
        "!python run_squad.py.1 \\\n",
        "    --model_type albert \\\n",
        "    --model_name_or_path ./model4 \\\n",
        "    --do_eval \\\n",
        "    --do_lower_case \\\n",
        "    --version_2_with_negative \\\n",
        "    --predict_file ./dev-v2.0.json \\\n",
        "    --max_seq_length 512 \\\n",
        "    --n_best_size=20 \\\n",
        "    --max_answer_length=30 \\\n",
        "    --doc_stride 128 \\\n",
        "    --max_query_length=64 \\\n",
        "    --per_gpu_eval_batch_size=16 \\\n",
        "    --output_dir ../prediction4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-27 12:52:21.509862: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/27/2020 12:52:23 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "[INFO|configuration_utils.py:411] 2020-11-27 12:52:23,220 >> loading configuration file ./model4/config.json\n",
            "[INFO|configuration_utils.py:449] 2020-11-27 12:52:23,220 >> Model config AlbertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:411] 2020-11-27 12:52:23,221 >> loading configuration file ./model4/config.json\n",
            "[INFO|configuration_utils.py:449] 2020-11-27 12:52:23,221 >> Model config AlbertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1577] 2020-11-27 12:52:23,221 >> Model name './model4' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming './model4' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "[INFO|tokenization_utils_base.py:1607] 2020-11-27 12:52:23,222 >> Didn't find file ./model4/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1607] 2020-11-27 12:52:23,222 >> Didn't find file ./model4/special_tokens_map.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1607] 2020-11-27 12:52:23,222 >> Didn't find file ./model4/tokenizer_config.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1607] 2020-11-27 12:52:23,222 >> Didn't find file ./model4/tokenizer.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1648] 2020-11-27 12:52:23,222 >> loading file ./model4/spiece.model\n",
            "[INFO|tokenization_utils_base.py:1648] 2020-11-27 12:52:23,222 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1648] 2020-11-27 12:52:23,222 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1648] 2020-11-27 12:52:23,222 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1648] 2020-11-27 12:52:23,222 >> loading file None\n",
            "[INFO|modeling_utils.py:938] 2020-11-27 12:52:23,266 >> loading weights file ./model4/pytorch_model.bin\n",
            "[WARNING|modeling_utils.py:1048] 2020-11-27 12:52:29,064 >> Some weights of the model checkpoint at ./model4 were not used when initializing AlbertForQuestionAnswering: ['has_ans.1.weight', 'has_ans.1.bias']\n",
            "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[INFO|modeling_utils.py:1065] 2020-11-27 12:52:29,064 >> All the weights of AlbertForQuestionAnswering were initialized from the model checkpoint at ./model4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertForQuestionAnswering for predictions without further training.\n",
            "11/27/2020 12:52:33 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir=None, device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=False, doc_stride=128, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, lang_id=0, learning_rate=5e-05, local_rank=-1, logging_steps=500, max_answer_length=30, max_grad_norm=1.0, max_query_length=64, max_seq_length=512, max_steps=-1, model_name_or_path='./model4', model_type='albert', n_best_size=20, n_gpu=1, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=3.0, output_dir='../prediction4', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=8, predict_file='./dev-v2.0.json', save_steps=500, seed=42, server_ip='', server_port='', threads=1, tokenizer_name='', train_file=None, verbose_logging=False, version_2_with_negative=True, warmup_steps=0, weight_decay=0.0)\n",
            "11/27/2020 12:52:33 - INFO - __main__ -   Loading checkpoint ./model4 for evaluation\n",
            "11/27/2020 12:52:33 - INFO - __main__ -   Evaluate the following checkpoints: ['./model4']\n",
            "[INFO|configuration_utils.py:411] 2020-11-27 12:52:33,093 >> loading configuration file ./model4/config.json\n",
            "[INFO|configuration_utils.py:449] 2020-11-27 12:52:33,093 >> Model config AlbertConfig {\n",
            "  \"attention_probs_dropout_prob\": 0,\n",
            "  \"bos_token_id\": 2,\n",
            "  \"classifier_dropout_prob\": 0.1,\n",
            "  \"down_scale_factor\": 1,\n",
            "  \"embedding_size\": 128,\n",
            "  \"eos_token_id\": 3,\n",
            "  \"gap_size\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0,\n",
            "  \"hidden_size\": 4096,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"inner_group_num\": 1,\n",
            "  \"intermediate_size\": 16384,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"layers_to_keep\": [],\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"albert\",\n",
            "  \"net_structure_type\": 0,\n",
            "  \"num_attention_heads\": 64,\n",
            "  \"num_hidden_groups\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_memory_blocks\": 0,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:938] 2020-11-27 12:52:33,094 >> loading weights file ./model4/pytorch_model.bin\n",
            "[WARNING|modeling_utils.py:1048] 2020-11-27 12:52:38,730 >> Some weights of the model checkpoint at ./model4 were not used when initializing AlbertForQuestionAnswering: ['has_ans.1.weight', 'has_ans.1.bias']\n",
            "- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[INFO|modeling_utils.py:1065] 2020-11-27 12:52:38,730 >> All the weights of AlbertForQuestionAnswering were initialized from the model checkpoint at ./model4.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use AlbertForQuestionAnswering for predictions without further training.\n",
            "11/27/2020 12:52:38 - INFO - __main__ -   Loading features from cached file ./cached_dev_model4_512\n",
            "Traceback (most recent call last):\n",
            "  File \"run_squad.py.1\", line 830, in <module>\n",
            "    main()\n",
            "  File \"run_squad.py.1\", line 819, in main\n",
            "    result = evaluate(args, model, tokenizer, prefix=global_step)\n",
            "  File \"run_squad.py.1\", line 271, in evaluate\n",
            "    dataset, examples, features = load_and_cache_examples(args, tokenizer, evaluate=True, output_examples=True)\n",
            "  File \"run_squad.py.1\", line 427, in load_and_cache_examples\n",
            "    features_and_dataset[\"examples\"],\n",
            "KeyError: 'examples'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLUd4QLGvz_P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}